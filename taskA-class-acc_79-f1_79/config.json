{
  "_name_or_path": "./bart-large-samsum-MediQA-augmented1k-taskA-genlen512",
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.1,
  "classifier_dropout": 0.0,
  "d_model": 1024,
  "decoder_attention_heads": 16,
  "decoder_ffn_dim": 4096,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 12,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "encoder_attention_heads": 16,
  "encoder_ffn_dim": 4096,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 12,
  "eos_token_id": 2,
  "forced_bos_token_id": 0,
  "forced_eos_token_id": 2,
  "gradient_checkpointing": false,
  "id2label": {
    "0": "OTHER_HISTORY",
    "1": "DISPOSITION",
    "2": "ALLERGY",
    "3": "PROCEDURES",
    "4": "EXAM",
    "5": "IMAGING",
    "6": "PASTMEDICALHX",
    "7": "MEDICATIONS",
    "8": "LABS",
    "9": "GYNHX",
    "10": "EDCOURSE",
    "11": "ASSESSMENT",
    "12": "GENHX",
    "13": "ROS",
    "14": "IMMUNIZATIONS",
    "15": "FAM/SOCHX",
    "16": "PLAN",
    "17": "PASTSURGICAL",
    "18": "CC",
    "19": "DIAGNOSIS"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "ALLERGY": 2,
    "ASSESSMENT": 11,
    "CC": 18,
    "DIAGNOSIS": 19,
    "DISPOSITION": 1,
    "EDCOURSE": 10,
    "EXAM": 4,
    "FAM/SOCHX": 15,
    "GENHX": 12,
    "GYNHX": 9,
    "IMAGING": 5,
    "IMMUNIZATIONS": 14,
    "LABS": 8,
    "MEDICATIONS": 7,
    "OTHER_HISTORY": 0,
    "PASTMEDICALHX": 6,
    "PASTSURGICAL": 17,
    "PLAN": 16,
    "PROCEDURES": 3,
    "ROS": 13
  },
  "max_position_embeddings": 1024,
  "model_type": "bart",
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "num_beams": 4,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "problem_type": "single_label_classification",
  "scale_embedding": false,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.27.1",
  "use_cache": true,
  "vocab_size": 50265
}
